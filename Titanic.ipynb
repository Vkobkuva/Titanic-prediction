{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "u2DGOcp0tJjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_df(train_data, test_data):\n",
        "    # Returns a concatenated df of training and test set\n",
        "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
        "\n",
        "def divide_df(all_data):\n",
        "    # Returns divided dfs of training and test set\n",
        "    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n",
        "\n",
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_test = pd.read_csv('/content/test.csv')\n",
        "df_all = concat_df(df_train, df_test)\n",
        "\n",
        "df_train.name = 'Training Set'\n",
        "df_test.name = 'Test Set'\n",
        "df_all.name = 'All Set'\n",
        "\n",
        "dfs = [df_train, df_test]\n",
        "\n",
        "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
        "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
        "print('Training X Shape = {}'.format(df_train.shape))\n",
        "print('Training y Shape = {}\\n'.format(df_train['Survived'].shape[0]))\n",
        "print('Test X Shape = {}'.format(df_test.shape))\n",
        "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
        "print(df_train.columns)\n",
        "print(df_test.columns)"
      ],
      "metadata": {
        "id": "FaZMJRQwtNBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.info())\n",
        "df_train.sample(3)"
      ],
      "metadata": {
        "id": "xJJRB8qAtaua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_test.info())\n",
        "df_test.sample(3)"
      ],
      "metadata": {
        "id": "7it3ncUGtcd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_missing(df):\n",
        "    for col in df.columns.tolist():\n",
        "        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
        "    print('\\n')\n",
        "\n",
        "for df in dfs:\n",
        "    print('{}'.format(df.name))\n",
        "    display_missing(df)"
      ],
      "metadata": {
        "id": "iP3OU68HtdSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_corr = df_all.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
        "df_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
        "df_all_corr[df_all_corr['Feature 1'] == 'Age']"
      ],
      "metadata": {
        "id": "PhRq69iItgWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
        "\n",
        "for pclass in range(1, 4):\n",
        "    for sex in ['female', 'male']:\n",
        "        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n",
        "print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n",
        "\n",
        "# Filling the missing values in Age with the medians of Sex and Pclass groups\n",
        "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
      ],
      "metadata": {
        "id": "2uwfY3g_tj_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all[df_all['Embarked'].isnull()]"
      ],
      "metadata": {
        "id": "anZNros4tlye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing values in Embarked with S\n",
        "df_all['Embarked'] = df_all['Embarked'].fillna('S')"
      ],
      "metadata": {
        "id": "2fCD3L7htoFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all[df_all['Fare'].isnull()]"
      ],
      "metadata": {
        "id": "dz0KTVjRtmvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
        "# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\n",
        "df_all['Fare'] = df_all['Fare'].fillna(med_fare)"
      ],
      "metadata": {
        "id": "-AfV5s5ktsFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\n",
        "df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
        "\n",
        "df_all_decks = df_all.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch',\n",
        "                                                                        'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()\n",
        "\n",
        "def get_pclass_dist(df):\n",
        "\n",
        "    # Creating a dictionary for every passenger class count in every deck\n",
        "    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n",
        "    decks = df.columns.levels[0]\n",
        "\n",
        "    for deck in decks:\n",
        "        for pclass in range(1, 4):\n",
        "            try:\n",
        "                count = df[deck][pclass][0]\n",
        "                deck_counts[deck][pclass] = count\n",
        "            except KeyError:\n",
        "                deck_counts[deck][pclass] = 0\n",
        "\n",
        "    df_decks = pd.DataFrame(deck_counts)\n",
        "    deck_percentages = {}\n",
        "\n",
        "    # Creating a dictionary for every passenger class percentage in every deck\n",
        "    for col in df_decks.columns:\n",
        "        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n",
        "\n",
        "    return deck_counts, deck_percentages\n",
        "\n",
        "def display_pclass_dist(percentages):\n",
        "\n",
        "    df_percentages = pd.DataFrame(percentages).transpose()\n",
        "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n",
        "    bar_count = np.arange(len(deck_names))\n",
        "    bar_width = 0.85\n",
        "\n",
        "    pclass1 = df_percentages[0]\n",
        "    pclass2 = df_percentages[1]\n",
        "    pclass3 = df_percentages[2]\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.bar(bar_count, pclass1, color='orange', edgecolor='blue', width=bar_width, label='Passenger Class 1')\n",
        "    plt.bar(bar_count, pclass2, bottom=pclass1, color='red', edgecolor='blue', width=bar_width, label='Passenger Class 2')\n",
        "    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='Green', edgecolor='blue', width=bar_width, label='Passenger Class 3')\n",
        "\n",
        "    plt.xlabel('Deck', size=15, labelpad=20)\n",
        "    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n",
        "    plt.xticks(bar_count, deck_names)\n",
        "    plt.tick_params(axis='x', labelsize=15)\n",
        "    plt.tick_params(axis='y', labelsize=15)\n",
        "\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n",
        "    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\n",
        "display_pclass_dist(all_deck_per)"
      ],
      "metadata": {
        "id": "GgsafPTUtws5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passenger in the T deck is changed to A\n",
        "idx = df_all[df_all['Deck'] == 'T'].index\n",
        "df_all.loc[idx, 'Deck'] = 'A'"
      ],
      "metadata": {
        "id": "8pTY5z6UuYZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_decks_survived = df_all.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
        "                                                                                   'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name':'Count'}).transpose()\n",
        "\n",
        "def get_survived_dist(df):\n",
        "\n",
        "    # Creating a dictionary for every survival count in every deck\n",
        "    surv_counts = {'A':{}, 'B':{}, 'C':{}, 'D':{}, 'E':{}, 'F':{}, 'G':{}, 'M':{}}\n",
        "    decks = df.columns.levels[0]\n",
        "\n",
        "    for deck in decks:\n",
        "        for survive in range(0, 2):\n",
        "            surv_counts[deck][survive] = df[deck][survive][0]\n",
        "\n",
        "    df_surv = pd.DataFrame(surv_counts)\n",
        "    surv_percentages = {}\n",
        "\n",
        "    for col in df_surv.columns:\n",
        "        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]\n",
        "\n",
        "    return surv_counts, surv_percentages\n",
        "\n",
        "def display_surv_dist(percentages):\n",
        "\n",
        "    df_survived_percentages = pd.DataFrame(percentages).transpose()\n",
        "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n",
        "    bar_count = np.arange(len(deck_names))\n",
        "    bar_width = 0.85\n",
        "\n",
        "    not_survived = df_survived_percentages[0]\n",
        "    survived = df_survived_percentages[1]\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.bar(bar_count, not_survived, color='red', edgecolor='white', width=bar_width, label=\"Not Survived\")\n",
        "    plt.bar(bar_count, survived, bottom=not_survived, color='blue', edgecolor='white', width=bar_width, label=\"Survived\")\n",
        "\n",
        "    plt.xlabel('Deck', size=15, labelpad=20)\n",
        "    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n",
        "    plt.xticks(bar_count, deck_names)\n",
        "    plt.tick_params(axis='x', labelsize=15)\n",
        "    plt.tick_params(axis='y', labelsize=15)\n",
        "\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n",
        "    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "all_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)\n",
        "display_surv_dist(all_surv_per)"
      ],
      "metadata": {
        "id": "mvamxbM-ubbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\n",
        "df_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\n",
        "df_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')\n",
        "\n",
        "df_all['Deck'].value_counts()"
      ],
      "metadata": {
        "id": "SqIEy55Nugh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the Cabin feature\n",
        "df_all.drop(['Cabin'], inplace=True, axis=1)\n",
        "\n",
        "df_train, df_test = divide_df(df_all)\n",
        "dfs = [df_train, df_test]\n",
        "\n",
        "for df in dfs:\n",
        "    display_missing(df)"
      ],
      "metadata": {
        "id": "32nv5R0gukrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "survived = df_train['Survived'].value_counts()[1]\n",
        "not_survived = df_train['Survived'].value_counts()[0]\n",
        "survived_per = survived / df_train.shape[0] * 100\n",
        "not_survived_per = not_survived / df_train.shape[0] * 100\n",
        "\n",
        "print('{} of {} passengers survived and it is the {:.2f}% of the training set.'.format(survived, df_train.shape[0], survived_per))\n",
        "print('{} of {} passengers didnt survive and it is the {:.2f}% of the training set.'.format(not_survived, df_train.shape[0], not_survived_per))\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.countplot(df_train['Survived'])\n",
        "\n",
        "plt.xlabel('Survival', size=15, labelpad=15)\n",
        "plt.ylabel('Passenger Count', size=15, labelpad=15)\n",
        "plt.xticks((0, 1), ['Not Survived ({0:.2f}%)'.format(not_survived_per), 'Survived ({0:.2f}%)'.format(survived_per)])\n",
        "plt.tick_params(axis='x', labelsize=13)\n",
        "plt.tick_params(axis='y', labelsize=13)\n",
        "\n",
        "plt.title('Training Set Survival Distribution', size=15, y=1.05)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MgBmHLEyunXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_corr = df_train.drop(['PassengerId'], axis=1).corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
        "df_train_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
        "df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)\n",
        "df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr['Correlation Coefficient'] == 1.0].index)\n",
        "\n",
        "df_test_corr = df_test.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
        "df_test_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
        "df_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)\n",
        "df_test_corr_nd = df_test_corr.drop(df_test_corr[df_test_corr['Correlation Coefficient'] == 1.0].index)"
      ],
      "metadata": {
        "id": "TLpW18-_u7-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set high correlations\n",
        "corr = df_train_corr_nd['Correlation Coefficient'] > 0.1\n",
        "df_train_corr_nd[corr]"
      ],
      "metadata": {
        "id": "5pPN4lOyu84n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set high correlations\n",
        "corr = df_test_corr_nd['Correlation Coefficient'] > 0.1\n",
        "df_test_corr_nd[corr]"
      ],
      "metadata": {
        "id": "oJCtsU4cu_ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
        "\n",
        "sns.heatmap(df_train.drop(['PassengerId'], axis=1).corr(), ax=axs[0], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
        "sns.heatmap(df_test.drop(['PassengerId'], axis=1).corr(), ax=axs[1], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
        "\n",
        "for i in range(2):\n",
        "    axs[i].tick_params(axis='x', labelsize=14)\n",
        "    axs[i].tick_params(axis='y', labelsize=14)\n",
        "\n",
        "axs[0].set_title('Training Set Correlations', size=15)\n",
        "axs[1].set_title('Test Set Correlations', size=15)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9zLHW0DSvBju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_features = ['Age', 'Fare']\n",
        "surv = df_train['Survived'] == 1\n",
        "\n",
        "fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))\n",
        "plt.subplots_adjust(right=1.5)\n",
        "\n",
        "for i, feature in enumerate(cont_features):\n",
        "    # Distribution of survival in feature\n",
        "    sns.distplot(df_train[~surv][feature], label='Not Survived', hist=True, color='#e74c3c', ax=axs[0][i])\n",
        "    sns.distplot(df_train[surv][feature], label='Survived', hist=True, color='#2ecc71', ax=axs[0][i])\n",
        "\n",
        "    # Distribution of feature in dataset\n",
        "    sns.distplot(df_train[feature], label='Training Set', hist=False, color='#e74c3c', ax=axs[1][i])\n",
        "    sns.distplot(df_test[feature], label='Test Set', hist=False, color='#2ecc71', ax=axs[1][i])\n",
        "\n",
        "    axs[0][i].set_xlabel('')\n",
        "    axs[1][i].set_xlabel('')\n",
        "\n",
        "    for j in range(2):\n",
        "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
        "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
        "\n",
        "    axs[0][i].legend(loc='upper right', prop={'size': 20})\n",
        "    axs[1][i].legend(loc='upper right', prop={'size': 20})\n",
        "    axs[0][i].set_title('Distribution of Survival in {}'.format(feature), size=20, y=1.05)\n",
        "\n",
        "axs[1][0].set_title('Distribution of {} Feature'.format('Age'), size=20, y=1.05)\n",
        "axs[1][1].set_title('Distribution of {} Feature'.format('Fare'), size=20, y=1.05)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z7IiBzV9vEZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Deck']\n",
        "\n",
        "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))\n",
        "plt.subplots_adjust(right=1.5, top=1.25)\n",
        "\n",
        "for i, feature in enumerate(cat_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.countplot(x=feature, hue='Survived', data=df_train)\n",
        "\n",
        "    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n",
        "    plt.ylabel('Passenger Count', size=20, labelpad=15)\n",
        "    plt.tick_params(axis='x', labelsize=20)\n",
        "    plt.tick_params(axis='y', labelsize=20)\n",
        "\n",
        "    plt.legend(['Not Survived', 'Survived'], loc='upper center', prop={'size': 18})\n",
        "    plt.title('Count of Survival in {} Feature'.format(feature), size=20, y=1.05)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rAXycpXLvIBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = concat_df(df_train, df_test)\n",
        "df_all.head()"
      ],
      "metadata": {
        "id": "6o0Na4novKx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)"
      ],
      "metadata": {
        "id": "GKRRK9ywvMb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(figsize=(22, 9))\n",
        "sns.countplot(x='Fare', hue='Survived', data=df_all)\n",
        "\n",
        "plt.xlabel('Fare', size=15, labelpad=20)\n",
        "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
        "plt.tick_params(axis='x', labelsize=10)\n",
        "plt.tick_params(axis='y', labelsize=15)\n",
        "\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
        "plt.title('Count of Survival in {} Feature'.format('Fare'), size=15, y=1.05)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SvsEsOyvvPtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['Age'] = pd.qcut(df_all['Age'], 10)"
      ],
      "metadata": {
        "id": "JjbAsLtivT00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(figsize=(22, 9))\n",
        "sns.countplot(x='Age', hue='Survived', data=df_all)\n",
        "\n",
        "plt.xlabel('Age', size=15, labelpad=20)\n",
        "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
        "plt.tick_params(axis='x', labelsize=15)\n",
        "plt.tick_params(axis='y', labelsize=15)\n",
        "\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
        "plt.title('Survival Counts in {} Feature'.format('Age'), size=15, y=1.05)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L-RDOhH7vWHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
        "\n",
        "fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)\n",
        "plt.subplots_adjust(right=1.5)\n",
        "\n",
        "sns.barplot(x=df_all['Family_Size'].value_counts().index, y=df_all['Family_Size'].value_counts().values, ax=axs[0][0])\n",
        "sns.countplot(x='Family_Size', hue='Survived', data=df_all, ax=axs[0][1])\n",
        "\n",
        "axs[0][0].set_title('Family Size Feature Value Counts', size=20, y=1.05)\n",
        "axs[0][1].set_title('Survival Counts in Family Size ', size=20, y=1.05)\n",
        "\n",
        "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
        "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
        "\n",
        "sns.barplot(x=df_all['Family_Size_Grouped'].value_counts().index, y=df_all['Family_Size_Grouped'].value_counts().values, ax=axs[1][0])\n",
        "sns.countplot(x='Family_Size_Grouped', hue='Survived', data=df_all, ax=axs[1][1])\n",
        "\n",
        "axs[1][0].set_title('Family Size Feature Value Counts After Grouping', size=20, y=1.05)\n",
        "axs[1][1].set_title('Survival Counts in Family Size After Grouping', size=20, y=1.05)\n",
        "\n",
        "for i in range(2):\n",
        "    axs[i][1].legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 20})\n",
        "    for j in range(2):\n",
        "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
        "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
        "        axs[i][j].set_xlabel('')\n",
        "        axs[i][j].set_ylabel('')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dCUa1GQSvXNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')"
      ],
      "metadata": {
        "id": "YXoiMf-Jvbnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(figsize=(12, 9))\n",
        "sns.countplot(x='Ticket_Frequency', hue='Survived', data=df_all)\n",
        "\n",
        "plt.xlabel('Ticket Frequency', size=15, labelpad=20)\n",
        "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
        "plt.tick_params(axis='x', labelsize=15)\n",
        "plt.tick_params(axis='y', labelsize=15)\n",
        "\n",
        "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
        "plt.title('Count of Survival in {} Feature'.format('Ticket Frequency'), size=15, y=1.05)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_pLKZLECvez1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
        "df_all['Is_Married'] = 0\n",
        "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1"
      ],
      "metadata": {
        "id": "ECdZytpBvhFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
        "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[0])\n",
        "\n",
        "axs[0].tick_params(axis='x', labelsize=10)\n",
        "axs[1].tick_params(axis='x', labelsize=15)\n",
        "\n",
        "for i in range(2):\n",
        "    axs[i].tick_params(axis='y', labelsize=15)\n",
        "\n",
        "axs[0].set_title('Title Feature Value Counts', size=20, y=1.05)\n",
        "\n",
        "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
        "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
        "\n",
        "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[1])\n",
        "axs[1].set_title('Title Feature Value Counts After Grouping', size=20, y=1.05)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0KXaNmAtvjAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_surname(data):\n",
        "\n",
        "    families = []\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        name = data.iloc[i]\n",
        "\n",
        "        if '(' in name:\n",
        "            name_no_bracket = name.split('(')[0]\n",
        "        else:\n",
        "            name_no_bracket = name\n",
        "\n",
        "        family = name_no_bracket.split(',')[0]\n",
        "        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n",
        "\n",
        "        for c in string.punctuation:\n",
        "            family = family.replace(c, '').strip()\n",
        "\n",
        "        families.append(family)\n",
        "\n",
        "    return families\n",
        "\n",
        "df_all['Family'] = extract_surname(df_all['Name'])\n",
        "df_train = df_all.loc[:890]\n",
        "df_test = df_all.loc[891:]\n",
        "dfs = [df_train, df_test]"
      ],
      "metadata": {
        "id": "Ydy1VErcvlyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of families and tickets that are occuring in both training and test set\n",
        "non_unique_families = [x for x in df_train['Family'].unique() if x in df_test['Family'].unique()]\n",
        "non_unique_tickets = [x for x in df_train['Ticket'].unique() if x in df_test['Ticket'].unique()]\n",
        "\n",
        "df_family_survival_rate = df_train.groupby('Family')['Survived', 'Family','Family_Size'].median()\n",
        "df_ticket_survival_rate = df_train.groupby('Ticket')['Survived', 'Ticket','Ticket_Frequency'].median()\n",
        "\n",
        "family_rates = {}\n",
        "ticket_rates = {}\n",
        "\n",
        "for i in range(len(df_family_survival_rate)):\n",
        "    # Checking a family exists in both training and test set, and has members more than 1\n",
        "    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n",
        "        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n",
        "\n",
        "for i in range(len(df_ticket_survival_rate)):\n",
        "    # Checking a ticket exists in both training and test set, and has members more than 1\n",
        "    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n",
        "        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]"
      ],
      "metadata": {
        "id": "euD28spXvomF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_survival_rate = np.mean(df_train['Survived'])\n",
        "\n",
        "train_family_survival_rate = []\n",
        "train_family_survival_rate_NA = []\n",
        "test_family_survival_rate = []\n",
        "test_family_survival_rate_NA = []\n",
        "\n",
        "for i in range(len(df_train)):\n",
        "    if df_train['Family'][i] in family_rates:\n",
        "        train_family_survival_rate.append(family_rates[df_train['Family'][i]])\n",
        "        train_family_survival_rate_NA.append(1)\n",
        "    else:\n",
        "        train_family_survival_rate.append(mean_survival_rate)\n",
        "        train_family_survival_rate_NA.append(0)\n",
        "\n",
        "for i in range(len(df_test)):\n",
        "    if df_test['Family'].iloc[i] in family_rates:\n",
        "        test_family_survival_rate.append(family_rates[df_test['Family'].iloc[i]])\n",
        "        test_family_survival_rate_NA.append(1)\n",
        "    else:\n",
        "        test_family_survival_rate.append(mean_survival_rate)\n",
        "        test_family_survival_rate_NA.append(0)\n",
        "\n",
        "df_train['Family_Survival_Rate'] = train_family_survival_rate\n",
        "df_train['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\n",
        "df_test['Family_Survival_Rate'] = test_family_survival_rate\n",
        "df_test['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n",
        "\n",
        "train_ticket_survival_rate = []\n",
        "train_ticket_survival_rate_NA = []\n",
        "test_ticket_survival_rate = []\n",
        "test_ticket_survival_rate_NA = []\n",
        "\n",
        "for i in range(len(df_train)):\n",
        "    if df_train['Ticket'][i] in ticket_rates:\n",
        "        train_ticket_survival_rate.append(ticket_rates[df_train['Ticket'][i]])\n",
        "        train_ticket_survival_rate_NA.append(1)\n",
        "    else:\n",
        "        train_ticket_survival_rate.append(mean_survival_rate)\n",
        "        train_ticket_survival_rate_NA.append(0)\n",
        "\n",
        "for i in range(len(df_test)):\n",
        "    if df_test['Ticket'].iloc[i] in ticket_rates:\n",
        "        test_ticket_survival_rate.append(ticket_rates[df_test['Ticket'].iloc[i]])\n",
        "        test_ticket_survival_rate_NA.append(1)\n",
        "    else:\n",
        "        test_ticket_survival_rate.append(mean_survival_rate)\n",
        "        test_ticket_survival_rate_NA.append(0)\n",
        "\n",
        "df_train['Ticket_Survival_Rate'] = train_ticket_survival_rate\n",
        "df_train['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\n",
        "df_test['Ticket_Survival_Rate'] = test_ticket_survival_rate\n",
        "df_test['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA"
      ],
      "metadata": {
        "id": "EAajXWlQvqtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [df_train, df_test]:\n",
        "    df['Survival_Rate'] = (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) / 2\n",
        "    df['Survival_Rate_NA'] = (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) / 2"
      ],
      "metadata": {
        "id": "JI5cpUK5vsOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
        "\n",
        "for df in dfs:\n",
        "    for feature in non_numeric_features:\n",
        "        df[feature] = LabelEncoder().fit_transform(df[feature])"
      ],
      "metadata": {
        "id": "7g5JB-iIvtrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
        "encoded_features = []\n",
        "\n",
        "for df in dfs:\n",
        "    for feature in cat_features:\n",
        "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
        "        n = df[feature].nunique()\n",
        "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
        "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
        "        encoded_df.index = df.index\n",
        "        encoded_features.append(encoded_df)\n",
        "\n",
        "df_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\n",
        "df_test = pd.concat([df_test, *encoded_features[6:]], axis=1)"
      ],
      "metadata": {
        "id": "iBxZX_UUvvOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = concat_df(df_train, df_test)\n",
        "drop_cols = ['Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n",
        "             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n",
        "            'Ticket_Survival_Rate', 'Family_Survival_Rate', 'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA']\n",
        "\n",
        "df_all.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "df_all.head()"
      ],
      "metadata": {
        "id": "WlCUOc6UvxQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
        "y_train = df_train['Survived'].values\n",
        "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
        "\n",
        "print('X_train shape: {}'.format(X_train.shape))\n",
        "print('y_train shape: {}'.format(y_train.shape))\n",
        "print('X_test shape: {}'.format(X_test.shape))"
      ],
      "metadata": {
        "id": "TiobvJU4vy_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_best_model = RandomForestClassifier(criterion='gini',\n",
        "                                           n_estimators=1100,\n",
        "                                           max_depth=5,\n",
        "                                           min_samples_split=4,\n",
        "                                           min_samples_leaf=5,\n",
        "                                           max_features='auto',\n",
        "                                           oob_score=True,\n",
        "                                           random_state=SEED,\n",
        "                                           n_jobs=-1,\n",
        "                                           verbose=1)\n",
        "\n",
        "leaderboard_model = RandomForestClassifier(criterion='gini',\n",
        "                                           n_estimators=1750,\n",
        "                                           max_depth=7,\n",
        "                                           min_samples_split=6,\n",
        "                                           min_samples_leaf=6,\n",
        "                                           max_features='auto',\n",
        "                                           oob_score=True,\n",
        "                                           random_state=SEED,\n",
        "                                           n_jobs=-1,\n",
        "                                           verbose=1)"
      ],
      "metadata": {
        "id": "3SdbbyNIv1JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 5\n",
        "oob = 0\n",
        "probs = pd.DataFrame(np.zeros((len(X_test), N * 2)), columns=['Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\n",
        "importances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=df_all.columns)\n",
        "fprs, tprs, scores = [], [], []\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
        "    print('Fold {}\\n'.format(fold))\n",
        "\n",
        "    # Fitting the model\n",
        "    leaderboard_model.fit(X_train[trn_idx], y_train[trn_idx])\n",
        "\n",
        "    # Computing Train AUC score\n",
        "    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx], leaderboard_model.predict_proba(X_train[trn_idx])[:, 1])\n",
        "    trn_auc_score = auc(trn_fpr, trn_tpr)\n",
        "    # Computing Validation AUC score\n",
        "    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx], leaderboard_model.predict_proba(X_train[val_idx])[:, 1])\n",
        "    val_auc_score = auc(val_fpr, val_tpr)\n",
        "\n",
        "    scores.append((trn_auc_score, val_auc_score))\n",
        "    fprs.append(val_fpr)\n",
        "    tprs.append(val_tpr)\n",
        "\n",
        "    # X_test probabilities\n",
        "    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 0]\n",
        "    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 1]\n",
        "    importances.iloc[:, fold - 1] = leaderboard_model.feature_importances_\n",
        "\n",
        "    oob += leaderboard_model.oob_score_ / N\n",
        "    print('Fold {} OOB Score: {}\\n'.format(fold, leaderboard_model.oob_score_))\n",
        "\n",
        "print('Average OOB Score: {}'.format(oob))"
      ],
      "metadata": {
        "id": "55_LG-kev2Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances['Mean_Importance'] = importances.mean(axis=1)\n",
        "importances.sort_values(by='Mean_Importance', inplace=True, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(15, 20))\n",
        "sns.barplot(x='Mean_Importance', y=importances.index, data=importances)\n",
        "\n",
        "plt.xlabel('')\n",
        "plt.tick_params(axis='x', labelsize=15)\n",
        "plt.tick_params(axis='y', labelsize=15)\n",
        "plt.title('Random Forest Classifier Mean Feature Importance Between Folds', size=15)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "188UViQ5v8v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(fprs, tprs):\n",
        "\n",
        "    tprs_interp = []\n",
        "    aucs = []\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    f, ax = plt.subplots(figsize=(15, 15))\n",
        "\n",
        "    # Plotting ROC for each fold and computing AUC scores\n",
        "    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n",
        "        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n",
        "        tprs_interp[-1][0] = 0.0\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        aucs.append(roc_auc)\n",
        "        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC Fold {} (AUC = {:.3f})'.format(i, roc_auc))\n",
        "\n",
        "    # Plotting ROC for random guessing\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random Guessing')\n",
        "\n",
        "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "\n",
        "    # Plotting the mean ROC\n",
        "    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n",
        "\n",
        "    # Plotting the standard deviation around the mean ROC Curve\n",
        "    std_tpr = np.std(tprs_interp, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n",
        "\n",
        "    ax.set_xlabel('False Positive Rate', size=15, labelpad=20)\n",
        "    ax.set_ylabel('True Positive Rate', size=15, labelpad=20)\n",
        "    ax.tick_params(axis='x', labelsize=15)\n",
        "    ax.tick_params(axis='y', labelsize=15)\n",
        "    ax.set_xlim([-0.05, 1.05])\n",
        "    ax.set_ylim([-0.05, 1.05])\n",
        "\n",
        "    ax.set_title('ROC Curves of Folds', size=20, y=1.02)\n",
        "    ax.legend(loc='lower right', prop={'size': 13})\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_curve(fprs, tprs)"
      ],
      "metadata": {
        "id": "l0mt0jaGv_3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_survived = [col for col in probs.columns if col.endswith('Prob_1')]\n",
        "probs['1'] = probs[class_survived].sum(axis=1) / N\n",
        "probs['0'] = probs.drop(columns=class_survived).sum(axis=1) / N\n",
        "probs['pred'] = 0\n",
        "pos = probs[probs['1'] >= 0.5].index\n",
        "probs.loc[pos, 'pred'] = 1\n",
        "\n",
        "y_pred = probs['pred'].astype(int)\n",
        "\n",
        "submission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
        "submission_df['PassengerId'] = df_test['PassengerId']\n",
        "submission_df['Survived'] = y_pred.values\n",
        "submission_df.to_csv('submissions.csv', header=True, index=False)\n",
        "submission_df.head(10)"
      ],
      "metadata": {
        "id": "ZIY445cqwCqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}